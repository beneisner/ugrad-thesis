Automatically generated by Mendeley Desktop 1.17.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{Funke.Jan2016,
author = {{Funke. Jan} and Saalfeld, Stephan and Bock, Davi and Turaga, Srini and Perlman, Eric},
title = {{CREMI: Circuit Reconstruction from Electron Microscopy Images}},
url = {https://cremi.org/},
urldate = {2017-03-01},
year = {2016}
}
@article{White1986,
abstract = {The structure and connectivity of the nervous system of the nematode Caenorhabditis elegans has been deduced from reconstructions of electron micrographs of serial sections. The hermaphrodite nervous system has a total complement of 302 neurons, which are arranged in an essentially invariant structure. Neurons with similar morphologies and connectivities have been grouped together into classes; there are 118 such classes. Neurons have simple morphologies with few, if any, branches. Processes from neurons run in defined positions within bundles of parallel processes, synaptic connections being made en passant. Process bundles are arranged longitudinally and circumferentially and are often adjacent to ridges of hypodermis. Neurons are generally highly locally connected, making synaptic connections with many of their neighbours. Muscle cells have arms that run out to process bundles containing motoneuron axons. Here they receive their synaptic input in defined regions along the surface of the bundles, where motoneuron axons reside. Most of the morphologically identifiable synaptic connections in a typical animal are described. These consist of about 5000 chemical synapses, 2000 neuromuscular junctions and 600 gap junctions.},
author = {White, J G and Southgate, E. and Thomson, J N and Brenner, S.},
doi = {10.1098/rstb.1986.0056},
isbn = {0962-8436 (Print)$\backslash$r0962-8436 (Linking)},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society of London},
number = {1165},
pages = {1--340},
pmid = {22462104},
title = {{The structure of the nervous system of the nematode Caenorhabditis elegans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22462104},
volume = {314},
year = {1986}
}
@article{Dosovitskiy2014,
abstract = {Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic features cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor.},
archivePrefix = {arXiv},
arxivId = {1406.6909},
author = {Dosovitskiy, Alexey and Fischer, Philipp and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
eprint = {1406.6909},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/Dosovitskiy et al. - 2014 - Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks.pdf:pdf},
month = {jun},
title = {{Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1406.6909},
year = {2014}
}
@misc{Arganda-Carreras2013,
author = {Arganda-Carreras, Ignacio and Seung, H. Sebastian and Vishwanathan, Ashwin and Vishwanathan, Daniel R. Berger},
title = {{ISBI 2013 challenge: 3D segmentation of neurites in EM images | SNEMI3D: 3D Segmentation of neurites in EM images}},
url = {http://brainiac2.mit.edu/SNEMI3D/home},
urldate = {2017-03-01},
year = {2013}
}
@article{Cicek2016,
abstract = {This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-fly elastic deformations for efficient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.},
archivePrefix = {arXiv},
arxivId = {1606.06650},
author = {{\c{C}}i{\c{c}}ek, {\"{O}}zg{\"{u}}n and Abdulkadir, Ahmed and Lienkamp, Soeren S. and Brox, Thomas and Ronneberger, Olaf},
eprint = {1606.06650},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/{\c{C}}i{\c{c}}ek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation from Sparse Annotation.pdf:pdf},
month = {jun},
title = {{3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation}},
url = {http://arxiv.org/abs/1606.06650},
year = {2016}
}
@article{Arganda-Carreras2015,
abstract = {To stimulate progress in automating the reconstruction of neural circuits, we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images, and were scored based on their agreement with ground truth from human experts. The winning team had no prior experience with EM images, and employed a convolutional network. This ``deep learning'' approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions, and the best so far has resulted from cooperation between two teams. The challenge has probably saturated, as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem, which should be useful for a future 3D segmentation challenge.},
author = {Arganda-Carreras, Ignacio and Turaga, Srinivas C. and Berger, Daniel R. and Cire≈üan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, J{\"{u}}rgen and Laptev, Dmitry and Dwivedi, Sarvesh and Buhmann, Joachim M. and Liu, Ting and Seyedhosseini, Mojtaba and Tasdizen, Tolga and Kamentsky, Lee and Burget, Radim and Uher, Vaclav and Tan, Xiao and Sun, Changming and Pham, Tuan D. and Bas, Erhan and Uzunbas, Mustafa G. and Cardona, Albert and Schindelin, Johannes and Seung, H. Sebastian},
doi = {10.3389/fnana.2015.00142},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/Arganda-Carreras et al. - 2015 - Crowdsourcing the creation of image segmentation algorithms for connectomics.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in Neuroanatomy},
keywords = {Electron microscopy,connectomics,image segmentation,machine learning,reconstruction},
month = {nov},
pages = {142},
publisher = {Frontiers},
title = {{Crowdsourcing the creation of image segmentation algorithms for connectomics}},
url = {http://journal.frontiersin.org/Article/10.3389/fnana.2015.00142/abstract},
volume = {9},
year = {2015}
}
@article{Long2014,
abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20{\%} relative improvement to 62.2{\%} mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
archivePrefix = {arXiv},
arxivId = {1411.4038},
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
eprint = {1411.4038},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/Long, Shelhamer, Darrell - 2014 - Fully Convolutional Networks for Semantic Segmentation.pdf:pdf},
month = {nov},
title = {{Fully Convolutional Networks for Semantic Segmentation}},
url = {http://arxiv.org/abs/1411.4038},
year = {2014}
}
@article{Januszewski2016,
abstract = {State-of-the-art image segmentation algorithms generally consist of at least two successive and distinct computations: a boundary detection process that uses local image information to classify image locations as boundaries between objects, followed by a pixel grouping step such as watershed or connected components that clusters pixels into segments. Prior work has varied the complexity and approach employed in these two steps, including the incorporation of multi-layer neural networks to perform boundary prediction, and the use of global optimizations during pixel clustering. We propose a unified and end-to-end trainable machine learning approach, flood-filling networks, in which a recurrent 3d convolutional network directly produces individual segments from a raw image. The proposed approach robustly segments images with an unknown and variable number of objects as well as highly variable object sizes. We demonstrate the approach on a challenging 3d image segmentation task, connectomic reconstruction from volume electron microscopy data, on which flood-filling neural networks substantially improve accuracy over other state-of-the-art methods. The proposed approach can replace complex multi-step segmentation pipelines with a single neural network that is learned end-to-end.},
archivePrefix = {arXiv},
arxivId = {1611.00421},
author = {Januszewski, Micha{\l} and Maitin-Shepard, Jeremy and Li, Peter and Kornfeld, J{\"{o}}rgen and Denk, Winfried and Jain, Viren},
eprint = {1611.00421},
file = {:Users/Ben/Google Drive/Research/References/Januszewski et al/Unknown/Januszewski et al. - 2016 - Flood-Filling Networks.pdf:pdf},
month = {nov},
title = {{Flood-Filling Networks}},
url = {http://arxiv.org/abs/1611.00421},
year = {2016}
}
@article{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
eprint = {1505.04597},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:pdf},
month = {may},
title = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
url = {http://arxiv.org/abs/1505.04597},
year = {2015}
}
@article{Nguyen2015,
abstract = {The ability to acquire large-scale recordings of neuronal activity in awake and unrestrained animals is needed to provide new insights into how populations of neurons generate animal behavior. We present an instrument capable of recording intracellular calcium transients from the majority of neurons in the head of a freely behaving Caenorhabditis elegans with cellular resolution while simultaneously recording the animal's position, posture, and locomotion. This instrument provides whole-brain imaging with cellular resolution in an unrestrained and behaving animal. We use spinning-disk confocal microscopy to capture 3D volumetric fluorescent images of neurons expressing the calcium indicator GCaMP6s at 6 head-volumes/s. A suite of three cameras monitor neuronal fluorescence and the animal's position and orientation. Custom software tracks the 3D position of the animal's head in real time and two feedback loops adjust a motorized stage and objective to keep the animal's head within the field of view as the animal roams freely. We observe calcium transients from up to 77 neurons for over 4 min and correlate this activity with the animal's behavior. We characterize noise in the system due to animal motion and show that, across worms, multiple neurons show significant correlations with modes of behavior corresponding to forward, backward, and turning locomotion.},
archivePrefix = {arXiv},
arxivId = {1501.03463},
author = {Nguyen, Jeffrey P and Shipley, Frederick B and Linder, Ashley N and Plummer, George S and Liu, Mochi and Setru, Sagar U and Shaevitz, Joshua W and Leifer, Andrew M},
doi = {10.1073/pnas.1507110112},
eprint = {1501.03463},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {9},
pages = {33},
pmid = {26712014},
title = {{Whole-brain calcium imaging with cellular resolution in freely behaving Caenorhabditis elegans.}},
url = {http://arxiv.org/abs/1501.03463},
year = {2015}
}
@article{Simard2003,
abstract = {Neural Networks are a powerful technology for classification of visual inputs arising from documents. However, there is a confusing plethora of different neural network methods that are used in the literature and in industry. This paper describes a set of concrete best practices that document analysis researchers can use to get good results with neural networks. The most important practice is that convolutional neural networks are better suited for visual document tasks than fully connected networks. We propose that a simple "do-it-yourself" implementation of convolution neural networks does not require complex methods, such as momentum, weight decay, structure-dependent learning rates, averaging layers, tangent prop, or even finely-tuning the architecture. The end result is a very simple yet general architecture which can yield state-of-the-art performance for document analysis. We illustrate our claims on the MNIST set of English digit images.},
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
doi = {10.1109/ICDAR.2003.1227801},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
keywords = {Best practices,Concrete,Convolution,Handwriting recognition,Industrial training,Information processing,Neural networks,Performance analysis,Support vector machines,Text analysis},
number = {Icdar},
pages = {958--963},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801},
volume = {1},
year = {2003}
}
@article{Kasthuri2015,
abstract = {We describe automated technologies to probe the structure of neural tissue at nanometer resolution and use them to generate a saturated reconstruction of a sub-volume of mouse neocortex in which all cellular objects (axons, dendrites, and glia) and many sub-cellular components (synapses, synaptic vesicles, spines, spine apparati, postsynaptic densities, and mitochondria) are rendered and itemized in a database. We explore these data to study physical properties of brain tissue. For example, by tracing the trajectories of all excitatory axons and noting their juxtapositions, both synaptic and non-synaptic, with every dendritic spine we refute the idea that physical proximity is sufficient to predict synaptic connectivity (the so-called Peters' rule). This online minable database provides general access to the intrinsic complexity of the neocortex and enables further data-driven inquiries. Video Abstract},
author = {Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, Jos?? Angel and Knowles-Barley, Seymour and Lee, Dongil and V??zquez-Reina, Amelio and Kaynig, Verena and Jones, Thouis Raymond and Roberts, Mike and Morgan, Josh Lyskowski and Tapia, Juan Carlos and Seung, H. Sebastian and Roncal, William Gray and Vogelstein, Joshua Tzvi and Burns, Randal and Sussman, Daniel Lewis and Priebe, Carey Eldin and Pfister, Hanspeter and Lichtman, Jeff William},
doi = {10.1016/j.cell.2015.06.054},
isbn = {1097-4172 (Electronic)$\backslash$r0092-8674 (Linking)},
issn = {10974172},
journal = {Cell},
number = {3},
pages = {648--661},
pmid = {26232230},
title = {{Saturated Reconstruction of a Volume of Neocortex}},
volume = {162},
year = {2015}
}
@article{Apthorpe2016,
abstract = {Calcium imaging is an important technique for monitoring the activity of thousands of neurons simultaneously. As calcium imaging datasets grow in size, automated detection of individual neurons is becoming important. Here we apply a supervised learning approach to this problem and show that convolutional networks can achieve near-human accuracy and superhuman speed. Accuracy is superior to the popular PCA/ICA method based on precision and recall relative to ground truth annotation by a human expert. These results suggest that convolutional networks are an efficient and flexible tool for the analysis of large-scale calcium imaging data.},
archivePrefix = {arXiv},
arxivId = {1606.07372},
author = {Apthorpe, Noah J. and Riordan, Alexander J. and Aguilar, Rob E. and Homann, Jan and Gu, Yi and Tank, David W. and Seung, H. Sebastian},
eprint = {1606.07372},
file = {:Users/Ben/Library/Application Support/Mendeley Desktop/Downloaded/Apthorpe et al. - 2016 - Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks.pdf:pdf},
month = {jun},
title = {{Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks}},
url = {http://arxiv.org/abs/1606.07372},
year = {2016}
}
